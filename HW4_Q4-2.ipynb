{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview:  HW3 - Question 4\n",
    "\n",
    "In this coding question, you'll implement a classifier with logistic regression\n",
    "$$ F(w) = \\frac{1}{N} \\sum_{i=1}^N \\log( 1 + e^{-\\langle w, x_i \\rangle y_i} ). $$\n",
    "\n",
    "For this problem, I would suggest using functions to prepare the dataset, run gradient descent, and return classification error.  By doing this, you only have to write the code one time and just use the functions to return results for part (4c)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading MNIST Data\n",
    "\n",
    "In this section, you will learn to load MNIST data.  If you do not have tensorflow available on your jupyter notebook, uncomment the next cell, run it, restart the kernel, and comment the next cell once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ngkarris/anaconda3/lib/python3.11/site-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (70000, 784) y shape: (70000,)\n"
     ]
    }
   ],
   "source": [
    "# this cell will take a minute to run depending on your internet connection\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True) # getting data from online\n",
    "print('X shape:', X.shape, 'y shape:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data with label 0 : (6903, 28, 28)\n",
      "Shape of data with label 1 : (7877, 28, 28)\n",
      "Shape of data with label 2 : (6990, 28, 28)\n",
      "Shape of data with label 3 : (7141, 28, 28)\n",
      "Shape of data with label 4 : (6824, 28, 28)\n",
      "Shape of data with label 5 : (6313, 28, 28)\n",
      "Shape of data with label 6 : (6876, 28, 28)\n",
      "Shape of data with label 7 : (7293, 28, 28)\n",
      "Shape of data with label 8 : (6825, 28, 28)\n",
      "Shape of data with label 9 : (6958, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# this cell processes some of the data\n",
    "\n",
    "# if this returns an error of the form \"KeyError: 0\", then try running the following first:\n",
    "# X = X.values # this converts X from a pandas dataframe to a numpy array\n",
    "\n",
    "digits = {j:[] for j in range(10)}\n",
    "for j in range(len(y)): # takes data assigns it into a dictionary\n",
    "    digits[int(y[j])].append(X[j].reshape(28,28))\n",
    "digits = {j:np.stack(digits[j]) for j in range(10)} # stack everything to be one numpy array\n",
    "for j in range(10):\n",
    "    print('Shape of data with label', j, ':', digits[j].shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell would stack 100 examples from each class together\n",
    "# this cell also ensures that each pixel is a flot between 0 and 1 instead of an int between 0 and 255\n",
    "data = []\n",
    "for i in range(10):\n",
    "    flattened_images = digits[i][:100].reshape(100,-1)\n",
    "    data.append(flattened_images)\n",
    "    \n",
    "data = np.vstack(data)\n",
    "data = data.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4a) Plotting\n",
    "\n",
    "Display one randomly selected image from your training data for each digit class. Provide the index number for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data here (this should have an output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4b) Label data\n",
    "\n",
    "Select the first 500 examples of 0’s and 1’s for this example, those will form the training data $(x_i , y_i) \\in \\mathbb{R}^{784} \\times \\{−1,1\\}, i = 1,...,1000$. Assign label $y_i = 1$ for 1s and $y_i = −1$ for 0s.  Also, renormalize your $x_i$ so that the pixel values are floats between 0 and 1, instead of ints from 0 to 255.  You can do this by augmenting the code given above for stacking data from different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset here (essentially just create a numpy array of 1's and -1's for the labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4c) Running Gradient Descent\n",
    "\n",
    "Implement and run a Gradient Descent algorithm, with step-size $\\mu = 10^{-4}$, to optimize the function above associated with this setup. You should run your algorithm for at least $T = 10,000$ iterations, but if your computer can handle it try $T=100,000$ or until a reasonable stopping criterion is satisfied.  Provide a plot showing the value of $F(w)$ at each iteration. Also, feel free to adjust $\\mu$ to be larger / smaller if the plot does not match your expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement gradient descent here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4d) Discussion about gradient descent\n",
    "\n",
    "Comment on the resulting plot. In particular, does the shape of $F(w)$ suggest you've successfully converged to a local or global minimum?  Does it appear you chose a good stopping criteria?  Explain whether your\n",
    "answers to these questions are consistent with the theory we discussed in class (and in the\n",
    "notes). Be specific i.e., point to a specific theorem (or theorems) and indicate\n",
    "why it does or does not explain the behavior of the algorithm.  Would the theory dictate a different choice of $\\mu$ than the one we used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put discussion here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the $w$ you found from part (a) to classify the first 500 \\emph{test} data points associated to\n",
    "each of the 0 and 1 handwritten digits. Recall that you need to use the function $y = \\text{sign}(w^T x)$\n",
    "to classify. What was the classification error rate associated with the two digits on the test\n",
    "data (this should be a number between 0 and 1)? What was it on the training data?  Does this relationship make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify and return the classification error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
